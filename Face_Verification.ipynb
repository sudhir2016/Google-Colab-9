{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_Verification",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMs4GJVCDxikPrlqETXflqD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudhir2016/Google-Colab-9/blob/master/Face_Verification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43SgugoVBvN6",
        "colab_type": "text"
      },
      "source": [
        "This is an example of using VGGFace for face verification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PHGt0eaPZAD",
        "colab_type": "text"
      },
      "source": [
        "It is assumed that directory named test of dataset of photos of 429 individuals with at least one photo each is uploaded in the notebook. I had used subset of LFW dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Y6j5Z5DCf-T",
        "colab_type": "text"
      },
      "source": [
        "Pip install VGGFace and MTCNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63KTMPktCoL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install keras_vggface"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGAiVvy5g8X5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install mtcnn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1Kz7oKTC1QG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Load various libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PrbjIb_BhYfP",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from PIL import Image\n",
        "from keras_vggface.vggface import VGGFace\n",
        "from keras_vggface.utils import preprocess_input\n",
        "from keras_vggface.utils import decode_predictions\n",
        "from mtcnn import MTCNN\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from scipy.spatial.distance import cosine\n",
        "import cv2\n",
        "import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmQF8-yyRJ0u",
        "colab_type": "text"
      },
      "source": [
        "Following to be used only for extracting from tar file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKd9mYuwrPNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import tarfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2Ctam8grLbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test=tarfile.open('face1.tgz')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WynnHiraswbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#test.extractall('/content')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EmwgFchhOxTK",
        "colab_type": "text"
      },
      "source": [
        "Create an empty list for labels and embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8YtNbd72CrG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label=[]\n",
        "emb=[]  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGkRwHxbOKNb",
        "colab_type": "text"
      },
      "source": [
        "Read folder names as labels and append to label list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVbbfwsMGY5y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for name in glob.glob('/content/test/*'):\n",
        "  name1=name[14:]\n",
        "  label.append(name1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOQPL09nOljZ",
        "colab_type": "text"
      },
      "source": [
        "Print label list and verify its length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ui9YpyntHCZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-Y12irNTcPb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "len(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg2V3jt9NSwy",
        "colab_type": "text"
      },
      "source": [
        "Define path head for os.path to generate full path for loading images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8mkUCk1NPlP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a='/content/test'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsqKsbEaN1F4",
        "colab_type": "text"
      },
      "source": [
        "Define detector as MTCNN and size as 224,224 for resizing image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W0c7QtWmN79v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detector=MTCNN()\n",
        "size=(224,224)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuvgV2C6MJ5F",
        "colab_type": "text"
      },
      "source": [
        "Load VGGFace with senet50 with include_top as false to be able to extract embeddings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2we1CyaS7XBQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vggface = VGGFace(model='senet50',include_top=False, input_shape=(224, 224, 3), pooling='avg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAVQQ0wbGDny",
        "colab_type": "text"
      },
      "source": [
        "Now we iteratively find the embeddings of all the 429 images in the dataset and add to the embedding list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uo9n38NrxyNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range (429):\n",
        "  b=label[i]\n",
        "  c=label[i]+'_0001.jpg'\n",
        "  d=os.path.join(a,b,c)\n",
        "  img1=plt.imread(d)  \n",
        "  out=detector.detect_faces(img1)\n",
        "  x1, y1, width, height = out[0]['box']\n",
        "  x2, y2 = x1 + width, y1 + height\n",
        "  face = img1[y1:y2, x1:x2]\n",
        "  img2 = Image.fromarray(face)\n",
        "  img3 = img2.resize(size)\n",
        "  img4 = np.array(img3)\n",
        "  img5 = img4.astype('float32')\n",
        "  img6=np.expand_dims(img5,axis=0)\n",
        "  img7 = preprocess_input(img6, version=2)\n",
        "  p=vggface.predict(img7)\n",
        "  emb.append(p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88Cp-iXiJNB-",
        "colab_type": "text"
      },
      "source": [
        "Display the last image processed by the model and verify the length of the emdedding list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhOOOVQnJkA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(img1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I96LO7e_J0Vw",
        "colab": {}
      },
      "source": [
        "len(emb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1Y3-_CxHMPJ",
        "colab_type": "text"
      },
      "source": [
        "We now need to identify a test case for our model. We choose Abel Pacheco (Ex president of Costa Rica) because the dataset has four photos for him. So we load and display the original photo of Abel Pacheco that we used to train the model and a new photo of his for testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_qU_kcYGlxz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_original = plt.imread('/content/test/Abel_Pacheco/Abel_Pacheco_0001.jpg')\n",
        "plt.imshow(test_original)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LTCOAoSGz7X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_new = plt.imread('/content/test/Abel_Pacheco/Abel_Pacheco_0002.jpg')\n",
        "plt.imshow(test_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eueiUjZSI7re",
        "colab_type": "text"
      },
      "source": [
        "We now run the new photo of Abel Pacheco through the model and obtain embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH31h1po-B0V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  out=detector.detect_faces(test_new)\n",
        "  x1, y1, width, height = out[0]['box']\n",
        "  x2, y2 = x1 + width, y1 + height\n",
        "  face = test_new[y1:y2, x1:x2]\n",
        "  img2 = Image.fromarray(face)\n",
        "  img3 = img2.resize(size)\n",
        "  img4 = np.array(img3)\n",
        "  img5 = img4.astype('float32')\n",
        "  img6=np.expand_dims(img5,axis=0)\n",
        "  img7 = preprocess_input(img6, version=2)\n",
        "  e=vggface.predict(img7)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUD2is4CEPdX",
        "colab_type": "text"
      },
      "source": [
        "We now iteratively check the Cosine distance between the embedding of the new photo of Abel Pacheco and embedding of all the images in the dataset. We declare a match in the case where the Cosine distance is found to be less than 0.4. We can see that the model has found the correct match and Cosine distance between original and new photo of Abel Pachico is 0.24."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nRXhTAPJpUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range (429):\n",
        "  s=cosine(e,emb[i])\n",
        "  if s < 0.4 :\n",
        "    l=label[i]\n",
        "    print('Match',i,l,s)  \n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}